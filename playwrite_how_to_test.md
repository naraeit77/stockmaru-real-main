Playwrightë¥¼ ì´ìš©í•œ StockMaru í”„ë¡œê·¸ë¨ ê²€ì¦ ê°€ì´ë“œ
Playwrightë¥¼ í™œìš©í•˜ì—¬ StockMaru AI ìë™ë§¤ë§¤ ì‹œìŠ¤í…œì„ ì²´ê³„ì ìœ¼ë¡œ ê²€ì¦í•˜ëŠ” ë°©ë²•ì„ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ğŸ“‹ ëª©ì°¨
Playwright ì†Œê°œ ë° ì„¤ì¹˜
í…ŒìŠ¤íŠ¸ ì „ëµ ìˆ˜ë¦½
FastAPI ì—”ë“œí¬ì¸íŠ¸ ê²€ì¦
ë°ì´í„°ë² ì´ìŠ¤ ë¬´ê²°ì„± ê²€ì¦
AI ì˜ˆì¸¡ ëª¨ë¸ ê²€ì¦
í•œêµ­íˆ¬ìì¦ê¶Œ API ì—°ë™ ê²€ì¦
E2E ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
ì„±ëŠ¥ ë° ë¶€í•˜ í…ŒìŠ¤íŠ¸
CI/CD íŒŒì´í”„ë¼ì¸ í†µí•©
1. Playwright ì†Œê°œ ë° ì„¤ì¹˜
Playwrightë€?
PlaywrightëŠ” Microsoftì—ì„œ ê°œë°œí•œ í¬ë¡œìŠ¤ ë¸Œë¼ìš°ì € ìë™í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, API í…ŒìŠ¤íŠ¸, UI í…ŒìŠ¤íŠ¸, ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ì§€ì›í•©ë‹ˆë‹¤. StockMaruì— ì í•©í•œ ì´ìœ :
âœ… FastAPI Swagger UI ìë™ í…ŒìŠ¤íŠ¸
âœ… API ì‘ë‹µ ì‹œê°„ ì¸¡ì •
âœ… ë¸Œë¼ìš°ì € ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ ê²€ì¦
âœ… ìŠ¤í¬ë¦°ìƒ·/ë¹„ë””ì˜¤ ìë™ ìº¡ì²˜ (ë²„ê·¸ ì¬í˜„)
ì„¤ì¹˜
# Playwright ì„¤ì¹˜
pip install playwright pytest-playwright

# ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ ì„¤ì¹˜
playwright install

# ì¶”ê°€ ì˜ì¡´ì„±
pip install pytest pytest-asyncio aiohttp
í”„ë¡œì íŠ¸ êµ¬ì¡°
stockmaru-real-main/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                 # Pytest ê³µí†µ ì„¤ì •
â”‚   â”œâ”€â”€ test_api_endpoints.py       # API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_database.py            # DB ê²€ì¦
â”‚   â”œâ”€â”€ test_ai_prediction.py       # AI ëª¨ë¸ ê²€ì¦
â”‚   â”œâ”€â”€ test_trading_logic.py       # ë§¤ë§¤ ë¡œì§ ê²€ì¦
â”‚   â”œâ”€â”€ test_integration.py         # í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_e2e_scenarios.py       # E2E ì‹œë‚˜ë¦¬ì˜¤
â”œâ”€â”€ playwright.config.py            # Playwright ì„¤ì •
â””â”€â”€ pytest.ini                      # Pytest ì„¤ì •
2. í…ŒìŠ¤íŠ¸ ì „ëµ ìˆ˜ë¦½
í…ŒìŠ¤íŠ¸ í”¼ë¼ë¯¸ë“œ
        /\
       /  \  E2E í…ŒìŠ¤íŠ¸ (10%)
      /    \  - ì „ì²´ ë§¤ë§¤ ì‹œë‚˜ë¦¬ì˜¤
     /------\
    /        \ í†µí•© í…ŒìŠ¤íŠ¸ (30%)
   /          \ - API + DB + ì™¸ë¶€ API
  /------------\
 /              \ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (60%)
/________________\ - ê°œë³„ í•¨ìˆ˜, ì—”ë“œí¬ì¸íŠ¸
í…ŒìŠ¤íŠ¸ ë²”ìœ„ ì •ì˜
ì¹´í…Œê³ ë¦¬	í…ŒìŠ¤íŠ¸ ëŒ€ìƒ	ìš°ì„ ìˆœìœ„
API ì—”ë“œí¬ì¸íŠ¸	GET/POST ì‘ë‹µ, ìƒíƒœ ì½”ë“œ, ë°ì´í„° í˜•ì‹	ë†’ìŒ
ë°ì´í„°ë² ì´ìŠ¤	CRUD ì‘ì—…, ë°ì´í„° ë¬´ê²°ì„±, íŠ¸ëœì­ì…˜	ë†’ìŒ
AI ì˜ˆì¸¡	ëª¨ë¸ ì •í™•ë„, ì˜ˆì¸¡ ë²”ìœ„, ì„±ëŠ¥	ì¤‘ê°„
ë§¤ë§¤ ë¡œì§	ë§¤ìˆ˜/ë§¤ë„ ì¡°ê±´, ë¦¬ìŠ¤í¬ ê´€ë¦¬	ë†’ìŒ
ì™¸ë¶€ API	í•œíˆ¬ API, Alpha Vantage, FRED	ì¤‘ê°„
ì„±ëŠ¥	ì‘ë‹µ ì‹œê°„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ë™ì‹œì„±	ë‚®ìŒ
3. FastAPI ì—”ë“œí¬ì¸íŠ¸ ê²€ì¦
3.1 ì„¤ì • íŒŒì¼ (conftest.py)
# tests/conftest.py
import pytest
import asyncio
from playwright.async_api import async_playwright
from fastapi.testclient import TestClient
from main import app
import os
from dotenv import load_dotenv

load_dotenv()

@pytest.fixture(scope="session")
def event_loop():
    """ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture(scope="session")
def test_client():
    """FastAPI í…ŒìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸"""
    return TestClient(app)

@pytest.fixture(scope="session")
async def browser():
    """Playwright ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤"""
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        yield browser
        await browser.close()

@pytest.fixture
async def page(browser):
    """ìƒˆë¡œìš´ í˜ì´ì§€ ì»¨í…ìŠ¤íŠ¸"""
    context = await browser.new_context()
    page = await context.new_page()
    yield page
    await context.close()

@pytest.fixture
def base_url():
    """API ë² ì´ìŠ¤ URL"""
    return os.getenv("API_BASE_URL", "http://localhost:8000")
3.2 API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
# tests/test_api_endpoints.py
import pytest
from playwright.async_api import expect
import time

class TestHealthCheck:
    """ì„œë²„ ìƒíƒœ í™•ì¸ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_root_endpoint(self, page, base_url):
        """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ì‘ë‹µ ê²€ì¦"""
        response = await page.goto(f"{base_url}/")
        
        # ìƒíƒœ ì½”ë“œ í™•ì¸
        assert response.status == 200
        
        # ì‘ë‹µ ë³¸ë¬¸ í™•ì¸
        content = await page.content()
        assert "Stock Prediction API is running" in content or "healthy" in content

    @pytest.mark.asyncio
    async def test_docs_page(self, page, base_url):
        """Swagger UI ì ‘ê·¼ í™•ì¸"""
        response = await page.goto(f"{base_url}/docs")
        
        assert response.status == 200
        await expect(page.locator("text=FastAPI")).to_be_visible()
        
        # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (ê²€ì¦ìš©)
        await page.screenshot(path="tests/screenshots/swagger_ui.png")


class TestBalanceEndpoints:
    """ì”ê³  ì¡°íšŒ API í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_get_balance(self, page, base_url):
        """ì”ê³  ì¡°íšŒ ì„±ê³µ ì¼€ì´ìŠ¤"""
        start_time = time.time()
        
        # API ìš”ì²­ ë° ì‘ë‹µ ìº¡ì²˜
        async with page.expect_response(f"{base_url}/balance") as response_info:
            await page.goto(f"{base_url}/balance")
        
        response = await response_info.value
        elapsed_time = time.time() - start_time
        
        # ìƒíƒœ ì½”ë“œ ê²€ì¦
        assert response.status == 200, f"Expected 200, got {response.status}"
        
        # ì‘ë‹µ ì‹œê°„ ê²€ì¦ (3ì´ˆ ì´ë‚´)
        assert elapsed_time < 3.0, f"Response time too slow: {elapsed_time:.2f}s"
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì¡° ê²€ì¦
        data = await response.json()
        assert "domestic_balance" in data or "overseas_balance" in data
        
        print(f"âœ… Balance API responded in {elapsed_time:.2f}s")

    @pytest.mark.asyncio
    async def test_balance_with_invalid_token(self, page, base_url):
        """ì˜ëª»ëœ í† í°ìœ¼ë¡œ ì ‘ê·¼ ì‹œ ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦"""
        # í™˜ê²½ ë³€ìˆ˜ ì„ì‹œ ë³€ê²½ (ëª¨í‚¹)
        response = await page.goto(f"{base_url}/balance?token=invalid_token")
        
        # 401 ë˜ëŠ” 403 ì˜ˆìƒ
        assert response.status in [401, 403, 500]


class TestStockDataEndpoints:
    """ì£¼ì‹ ë°ì´í„° API í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_get_stock_by_ticker(self, page, base_url):
        """íŠ¹ì • ì¢…ëª© ë°ì´í„° ì¡°íšŒ"""
        tickers = ["AAPL", "MSFT", "TSLA"]
        
        for ticker in tickers:
            response = await page.goto(f"{base_url}/stock/{ticker}")
            assert response.status == 200
            
            content = await page.text_content("body")
            assert ticker in content or "error" not in content.lower()
    
    @pytest.mark.asyncio
    async def test_get_predictions(self, page, base_url):
        """AI ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ"""
        response = await page.goto(f"{base_url}/predictions")
        
        assert response.status == 200
        
        data = await response.json()
        
        # ì˜ˆì¸¡ ë°ì´í„° êµ¬ì¡° ê²€ì¦
        if isinstance(data, dict) and "predictions" in data:
            predictions = data["predictions"]
            assert len(predictions) > 0, "No predictions found"
            
            # ì²« ë²ˆì§¸ ì˜ˆì¸¡ ë°ì´í„° ê²€ì¦
            first_pred = predictions[0]
            required_fields = ["ticker", "predicted_14d", "rise_probability", "accuracy"]
            
            for field in required_fields:
                assert field in first_pred, f"Missing field: {field}"
    
    @pytest.mark.asyncio
    async def test_update_data_endpoint(self, page, base_url):
        """ë°ì´í„° ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±° (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
        # POST ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
        response = await page.evaluate(f"""
            fetch('{base_url}/update_data', {{
                method: 'POST',
                headers: {{'Content-Type': 'application/json'}}
            }})
            .then(r => r.json())
        """)
        
        assert "message" in response
        assert "background" in response["message"].lower() or "started" in response["message"].lower()


class TestErrorHandling:
    """ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦"""
    
    @pytest.mark.asyncio
    async def test_404_not_found(self, page, base_url):
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸"""
        response = await page.goto(f"{base_url}/nonexistent_endpoint")
        assert response.status == 404
    
    @pytest.mark.asyncio
    async def test_invalid_ticker(self, page, base_url):
        """ì˜ëª»ëœ í‹°ì»¤ ìš”ì²­"""
        response = await page.goto(f"{base_url}/stock/INVALID123")
        
        # 404 ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜ ì˜ˆìƒ
        assert response.status in [404, 400, 500]
3.3 API ì‘ë‹µ ì‹œê°„ ëª¨ë‹ˆí„°ë§
# tests/test_performance.py
import pytest
import asyncio
import statistics

class TestAPIPerformance:
    """API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_balance_response_time(self, page, base_url):
        """ì”ê³  ì¡°íšŒ ì‘ë‹µ ì‹œê°„ ì¸¡ì • (10íšŒ í‰ê· )"""
        times = []
        
        for i in range(10):
            start = asyncio.get_event_loop().time()
            response = await page.goto(f"{base_url}/balance")
            end = asyncio.get_event_loop().time()
            
            if response.status == 200:
                times.append(end - start)
            
            await asyncio.sleep(0.5)  # Rate limiting ë°©ì§€
        
        avg_time = statistics.mean(times)
        std_dev = statistics.stdev(times)
        
        print(f"\nğŸ“Š Balance API Performance:")
        print(f"   Average: {avg_time:.3f}s")
        print(f"   Std Dev: {std_dev:.3f}s")
        print(f"   Min: {min(times):.3f}s")
        print(f"   Max: {max(times):.3f}s")
        
        # ì„±ëŠ¥ ê¸°ì¤€: í‰ê·  3ì´ˆ ì´ë‚´
        assert avg_time < 3.0, f"Average response time too slow: {avg_time:.2f}s"
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self, browser, base_url):
        """ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ëŠ¥ë ¥ (10ëª… ë™ì‹œ ì ‘ì†)"""
        async def make_request(context_id):
            context = await browser.new_context()
            page = await context.new_page()
            
            try:
                start = asyncio.get_event_loop().time()
                response = await page.goto(f"{base_url}/")
                end = asyncio.get_event_loop().time()
                
                return {
                    "context_id": context_id,
                    "status": response.status,
                    "time": end - start
                }
            finally:
                await context.close()
        
        # 10ê°œ ë™ì‹œ ìš”ì²­
        tasks = [make_request(i) for i in range(10)]
        results = await asyncio.gather(*tasks)
        
        # ëª¨ë“  ìš”ì²­ ì„±ê³µ í™•ì¸
        successful = [r for r in results if r["status"] == 200]
        assert len(successful) == 10, f"Only {len(successful)}/10 requests succeeded"
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„
        avg_time = statistics.mean([r["time"] for r in results])
        print(f"\nğŸ”„ Concurrent Requests (10 users):")
        print(f"   Success Rate: {len(successful)}/10")
        print(f"   Average Time: {avg_time:.3f}s")
4. ë°ì´í„°ë² ì´ìŠ¤ ë¬´ê²°ì„± ê²€ì¦
# tests/test_database.py
import pytest
from dbConnection import supabase
import pandas as pd
from datetime import datetime, timedelta

class TestDatabaseConnection:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    
    def test_supabase_connection(self):
        """Supabase ì—°ê²° í™•ì¸"""
        try:
            response = supabase.table("economic_and_stock_data").select("*").limit(1).execute()
            assert response.data is not None
            print("âœ… Supabase connection successful")
        except Exception as e:
            pytest.fail(f"Supabase connection failed: {e}")


class TestEconomicDataTable:
    """economic_and_stock_data í…Œì´ë¸” ê²€ì¦"""
    
    def test_table_exists(self):
        """í…Œì´ë¸” ì¡´ì¬ í™•ì¸"""
        response = supabase.table("economic_and_stock_data").select("ë‚ ì§œ").limit(1).execute()
        assert len(response.data) > 0
    
    def test_data_integrity(self):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        # ìµœê·¼ 30ì¼ ë°ì´í„° ì¡°íšŒ
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=30)
        
        response = supabase.table("economic_and_stock_data")\
            .select("*")\
            .gte("ë‚ ì§œ", str(start_date))\
            .lte("ë‚ ì§œ", str(end_date))\
            .execute()
        
        df = pd.DataFrame(response.data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        required_columns = ["ë‚ ì§œ", "ì• í”Œ", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "í…ŒìŠ¬ë¼", "ê¸°ì¤€ê¸ˆë¦¬"]
        for col in required_columns:
            assert col in df.columns, f"Missing column: {col}"
        
        # NULL ê°’ ë¹„ìœ¨ í™•ì¸ (10% ë¯¸ë§Œ)
        null_ratio = df.isnull().sum() / len(df)
        high_null_cols = null_ratio[null_ratio > 0.1]
        
        if len(high_null_cols) > 0:
            print(f"âš ï¸  Columns with >10% NULL: {high_null_cols.to_dict()}")
        
        # ì£¼ê°€ ë°ì´í„° ë²”ìœ„ ê²€ì¦ (0 ì´ìƒ)
        stock_columns = ["ì• í”Œ", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "í…ŒìŠ¬ë¼"]
        for col in stock_columns:
            if col in df.columns:
                assert (df[col] >= 0).all(), f"{col} has negative values"
    
    def test_date_continuity(self):
        """ë‚ ì§œ ì—°ì†ì„± ê²€ì¦ (ì£¼ë§ ì œì™¸)"""
        response = supabase.table("economic_and_stock_data")\
            .select("ë‚ ì§œ")\
            .order("ë‚ ì§œ", desc=False)\
            .limit(100)\
            .execute()
        
        dates = pd.to_datetime([r["ë‚ ì§œ"] for r in response.data])
        
        # ë‚ ì§œ ì •ë ¬ í™•ì¸
        assert (dates == dates.sort_values()).all(), "Dates are not sorted"
        
        # ì£¼ë§ ì œì™¸ ì—°ì†ì„± í™•ì¸
        business_days = pd.bdate_range(start=dates.min(), end=dates.max())
        missing_days = set(business_days) - set(dates)
        
        if len(missing_days) > 5:
            print(f"âš ï¸  {len(missing_days)} business days missing")


class TestPredictedStocksTable:
    """predicted_stocks í…Œì´ë¸” ê²€ì¦"""
    
    def test_prediction_accuracy(self):
        """ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚°"""
        response = supabase.table("predicted_stocks")\
            .select("*")\
            .limit(100)\
            .execute()
        
        df = pd.DataFrame(response.data)
        
        # Actualê³¼ Predicted ì»¬ëŸ¼ ë§¤ì¹­
        stock_names = ["ì• í”Œ", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "í…ŒìŠ¬ë¼"]
        
        for stock in stock_names:
            pred_col = f"{stock}_Predicted"
            actual_col = f"{stock}_Actual"
            
            if pred_col in df.columns and actual_col in df.columns:
                # NaN ì œê±°
                valid_data = df[[pred_col, actual_col]].dropna()
                
                if len(valid_data) > 0:
                    # MAPE ê³„ì‚°
                    mape = (abs(valid_data[pred_col] - valid_data[actual_col]) / valid_data[actual_col]).mean() * 100
                    
                    print(f"ğŸ“Š {stock} Prediction MAPE: {mape:.2f}%")
                    
                    # ì •í™•ë„ ê¸°ì¤€: MAPE < 20%
                    assert mape < 20, f"{stock} prediction accuracy too low: {mape:.2f}%"


class TestStockRecommendationsTable:
    """stock_recommendations í…Œì´ë¸” ê²€ì¦"""
    
    def test_technical_indicators_range(self):
        """ê¸°ìˆ ì  ì§€í‘œ ë²”ìœ„ ê²€ì¦"""
        response = supabase.table("stock_recommendations")\
            .select("*")\
            .limit(100)\
            .execute()
        
        df = pd.DataFrame(response.data)
        
        # RSI ë²”ìœ„ í™•ì¸ (0~100)
        if "RSI" in df.columns:
            rsi_values = df["RSI"].dropna()
            assert (rsi_values >= 0).all() and (rsi_values <= 100).all(), "RSI out of range"
        
        # Boolean í•„ë“œ ê²€ì¦
        boolean_fields = ["ê³¨ë“ _í¬ë¡œìŠ¤", "MACD_ë§¤ìˆ˜_ì‹ í˜¸", "ì¶”ì²œ_ì—¬ë¶€"]
        for field in boolean_fields:
            if field in df.columns:
                unique_values = df[field].dropna().unique()
                assert set(unique_values).issubset({True, False, 0, 1}), f"{field} has invalid values"
5. AI ì˜ˆì¸¡ ëª¨ë¸ ê²€ì¦
# tests/test_ai_prediction.py
import pytest
import numpy as np
import pandas as pd
from predict import build_transformer_with_two_inputs
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error

class TestTransformerModel:
    """Transformer ëª¨ë¸ ê²€ì¦"""
    
    def test_model_architecture(self):
        """ëª¨ë¸ êµ¬ì¡° ê²€ì¦"""
        stock_shape = (90, 27)  # 90ì¼ lookback, 27ê°œ ì¢…ëª©
        econ_shape = (90, 37)   # 90ì¼ lookback, 37ê°œ ê²½ì œ ì§€í‘œ
        
        model = build_transformer_with_two_inputs(
            stock_shape=stock_shape,
            econ_shape=econ_shape,
            num_heads=8,
            ff_dim=256,
            target_size=27
        )
        
        # ì…ë ¥ í˜•íƒœ í™•ì¸
        assert len(model.inputs) == 2, "Model should have 2 inputs"
        assert model.inputs[0].shape[1:] == stock_shape
        assert model.inputs[1].shape[1:] == econ_shape
        
        # ì¶œë ¥ í˜•íƒœ í™•ì¸
        assert model.output.shape[-1] == 27, "Output should predict 27 stocks"
        
        print(f"âœ… Model architecture valid")
        print(f"   Total parameters: {model.count_params():,}")
    
    def test_prediction_output_range(self):
        """ì˜ˆì¸¡ ê²°ê³¼ ë²”ìœ„ ê²€ì¦ (ìŒìˆ˜ ì£¼ê°€ ë°©ì§€)"""
        # ë”ë¯¸ ë°ì´í„° ìƒì„±
        X_stock = np.random.rand(10, 90, 27)
        X_econ = np.random.rand(10, 90, 37)
        
        model = build_transformer_with_two_inputs((90, 27), (90, 37), 8, 256, 27)
        predictions = model.predict([X_stock, X_econ])
        
        # ëª¨ë“  ì˜ˆì¸¡ê°’ì´ ìŠ¤ì¼€ì¼ë§ëœ ë²”ìœ„ (0~1) ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        assert predictions.min() >= 0, "Predictions contain negative values after scaling"
        assert predictions.max() <= 1, "Predictions exceed scaling range"
    
    def test_model_performance(self):
        """ì‹¤ì œ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        # Supabaseì—ì„œ ìµœê·¼ ë°ì´í„° ë¡œë“œ
        from dbConnection import supabase
        
        response = supabase.table("predicted_stocks")\
            .select("*")\
            .order("ë‚ ì§œ", desc=True)\
            .limit(100)\
            .execute()
        
        df = pd.DataFrame(response.data)
        
        stock_names = ["ì• í”Œ", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "í…ŒìŠ¬ë¼"]
        performance_report = {}
        
        for stock in stock_names:
            pred_col = f"{stock}_Predicted"
            actual_col = f"{stock}_Actual"
            
            if pred_col in df.columns and actual_col in df.columns:
                valid_data = df[[pred_col, actual_col]].dropna()
                
                if len(valid_data) > 10:
                    mae = mean_absolute_error(valid_data[actual_col], valid_data[pred_col])
                    mape = mean_absolute_percentage_error(valid_data[actual_col], valid_data[pred_col]) * 100
                    
                    performance_report[stock] = {
                        "MAE": round(mae, 2),
                        "MAPE": round(mape, 2),
                        "Accuracy": round(100 - mape, 2)
                    }
        
        print("\nğŸ“Š AI Model Performance Report:")
        for stock, metrics in performance_report.items():
            print(f"   {stock}:")
            print(f"      MAE: ${metrics['MAE']}")
            print(f"      MAPE: {metrics['MAPE']}%")
            print(f"      Accuracy: {metrics['Accuracy']}%")
            
            # ì •í™•ë„ ê¸°ì¤€: 80% ì´ìƒ
            assert metrics["Accuracy"] >= 80, f"{stock} accuracy below threshold"
6. í•œêµ­íˆ¬ìì¦ê¶Œ API ì—°ë™ ê²€ì¦
# tests/test_trading_api.py
import pytest
from getBalance import get_token, get_overseas_balance
import os
from datetime import datetime, timezone
import pytz

class TestKoreaInvestmentAPI:
    """í•œêµ­íˆ¬ìì¦ê¶Œ API í…ŒìŠ¤íŠ¸"""
    
    def test_token_generation(self):
        """í† í° ìƒì„± ê²€ì¦"""
        token = get_token()
        
        assert token is not None, "Token generation failed"
        assert len(token) > 50, "Token seems invalid (too short)"
        
        print(f"âœ… Token generated: {token[:20]}...")
    
    def test_token_expiration_logic(self):
        """í† í° ë§Œë£Œ ë¡œì§ ê²€ì¦"""
        from dbConnection import supabase
        
        # DBì—ì„œ í† í° ì¡°íšŒ
        response = supabase.table("access_tokens")\
            .select("*")\
            .order("ìƒì„±ì¼", desc=True)\
            .limit(1)\
            .execute()
        
        if len(response.data) > 0:
            token_data = response.data[0]
            created_at = datetime.fromisoformat(token_data["ìƒì„±ì¼"].replace("Z", "+00:00"))
            now = datetime.now(pytz.UTC)
            
            age_hours = (now - created_at).total_seconds() / 3600
            
            print(f"ğŸ“… Token age: {age_hours:.2f} hours")
            
            # 24ì‹œê°„ ì´ìƒì´ë©´ ë§Œë£Œ ì˜ˆìƒ
            if age_hours >= 24:
                print("âš ï¸  Token should be expired, will refresh")
    
    @pytest.mark.skipif(
        os.getenv("KIS_APPKEY") is None,
        reason="Korea Investment API keys not configured"
    )
    def test_balance_inquiry(self):
        """ì”ê³  ì¡°íšŒ API í˜¸ì¶œ"""
        try:
            balance = get_overseas_balance()
            
            assert balance is not None, "Balance inquiry failed"
            
            # ì‘ë‹µ êµ¬ì¡° ê²€ì¦
            if isinstance(balance, dict):
                print(f"ğŸ’° Overseas Balance Retrieved:")
                if "output1" in balance:
                    stocks = balance["output1"]
                    print(f"   Positions: {len(stocks)}")
        
        except Exception as e:
            pytest.skip(f"API call failed (expected in test env): {e}")
    
    def test_api_error_handling(self):
        """API ì˜¤ë¥˜ ì²˜ë¦¬ ê²€ì¦"""
        # ì˜ëª»ëœ AppKeyë¡œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
        import requests
        
        url = "https://openapivts.koreainvestment.com:29443/oauth2/tokenP"
        headers = {"Content-Type": "application/json"}
        body = {
            "grant_type": "client_credentials",
            "appkey": "INVALID_KEY",
            "appsecret": "INVALID_SECRET"
        }
        
        response = requests.post(url, json=body, headers=headers)
        
        # 401 ë˜ëŠ” 400 ì—ëŸ¬ ì˜ˆìƒ
        assert response.status_code in [400, 401], "Expected authentication error"
        print(f"âœ… Error handling works: {response.status_code}")
7. E2E ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
# tests/test_e2e_scenarios.py
import pytest
from playwright.async_api import async_playwright
import asyncio

class TestTradingWorkflow:
    """ì „ì²´ ë§¤ë§¤ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_full_trading_cycle(self, page, base_url):
        """
        E2E ì‹œë‚˜ë¦¬ì˜¤: ë°ì´í„° ìˆ˜ì§‘ â†’ ì˜ˆì¸¡ â†’ ì¶”ì²œ â†’ ë§¤ìˆ˜
        """
        print("\nğŸ”„ Starting Full Trading Cycle Test...")
        
        # Step 1: ì„œë²„ ìƒíƒœ í™•ì¸
        print("1ï¸âƒ£  Checking server health...")
        response = await page.goto(f"{base_url}/")
        assert response.status == 200
        
        # Step 2: ì”ê³  ì¡°íšŒ
        print("2ï¸âƒ£  Fetching account balance...")
        await page.goto(f"{base_url}/balance")
        balance_content = await page.content()
        assert "error" not in balance_content.lower()
        
        # Step 3: AI ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
        print("3ï¸âƒ£  Retrieving AI predictions...")
        await page.goto(f"{base_url}/predictions")
        predictions = await page.evaluate("JSON.parse(document.body.innerText)")
        
        assert "predictions" in predictions or isinstance(predictions, list)
        
        # Step 4: ë§¤ìˆ˜ ì¶”ì²œ ì¢…ëª© í™•ì¸
        print("4ï¸âƒ£  Checking buy recommendations...")
        # ì¶”ì²œ APIê°€ ìˆë‹¤ë©´ í˜¸ì¶œ
        # await page.goto(f"{base_url}/recommendations")
        
        # Step 5: ì‹¤ì œ ë§¤ìˆ˜ ì‹œë®¬ë ˆì´ì…˜ (ëª¨ì˜íˆ¬ì)
        print("5ï¸âƒ£  Simulating buy order...")
        # POST ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
        # await page.evaluate(...)
        
        print("âœ… Full trading cycle completed successfully")
    
    @pytest.mark.asyncio
    async def test_data_update_workflow(self, page, base_url):
        """
        ë°ì´í„° ì—…ë°ì´íŠ¸ ì›Œí¬í”Œë¡œìš°
        """
        print("\nğŸ”„ Testing Data Update Workflow...")
        
        # ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
        response = await page.evaluate(f"""
            fetch('{base_url}/update_data', {{
                method: 'POST'
            }})
            .then(r => r.json())
        """)
        
        assert "started" in response["message"].lower() or "background" in response["message"].lower()
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 5ë¶„)
        print("â³ Waiting for background task (max 5min)...")
        
        for i in range(30):  # 10ì´ˆ ê°„ê²©ìœ¼ë¡œ 30íšŒ í™•ì¸
            await asyncio.sleep(10)
            
            # ìµœì‹  ë°ì´í„° í™•ì¸
            await page.goto(f"{base_url}/predictions")
            content = await page.content()
            
            if "predictions" in content or len(content) > 100:
                print(f"âœ… Data update completed after {(i+1)*10} seconds")
                break
        else:
            pytest.skip("Data update took longer than 5 minutes")
    
    @pytest.mark.asyncio
    async def test_error_recovery(self, page, base_url):
        """
        ì—ëŸ¬ ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤
        """
        # ì˜ëª»ëœ ìš”ì²­ ì „ì†¡
        response = await page.goto(f"{base_url}/stock/INVALID_TICKER_12345")
        
        # ì—ëŸ¬ ì‘ë‹µ í™•ì¸
        assert response.status in [400, 404, 500]
        
        # ì •ìƒ ìš”ì²­ìœ¼ë¡œ ë³µêµ¬ í™•ì¸
        response = await page.goto(f"{base_url}/stock/AAPL")
        assert response.status == 200
        
        print("âœ… Error recovery successful")
8. ì„±ëŠ¥ ë° ë¶€í•˜ í…ŒìŠ¤íŠ¸
# tests/test_load_testing.py
import pytest
import asyncio
import time
from playwright.async_api import async_playwright

class TestLoadTesting:
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_stress_test(self, base_url):
        """ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸: 100ëª… ë™ì‹œ ì ‘ì†"""
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            
            async def user_session(user_id):
                context = await browser.new_context()
                page = await context.new_page()
                
                start = time.time()
                
                try:
                    # ë£¨íŠ¸ í˜ì´ì§€ ì ‘ì†
                    await page.goto(base_url, wait_until="domcontentloaded", timeout=10000)
                    
                    # ì”ê³  ì¡°íšŒ
                    await page.goto(f"{base_url}/balance", wait_until="domcontentloaded", timeout=10000)
                    
                    # ì˜ˆì¸¡ ì¡°íšŒ
                    await page.goto(f"{base_url}/predictions", wait_until="domcontentloaded", timeout=10000)
                    
                    elapsed = time.time() - start
                    
                    return {
                        "user_id": user_id,
                        "success": True,
                        "time": elapsed
                    }
                
                except Exception as e:
                    return {
                        "user_id": user_id,
                        "success": False,
                        "error": str(e)
                    }
                
                finally:
                    await context.close()
            
            # 100ëª… ë™ì‹œ ì ‘ì†
            print("\nğŸš€ Starting stress test with 100 concurrent users...")
            tasks = [user_session(i) for i in range(100)]
            results = await asyncio.gather(*tasks)
            
            await browser.close()
            
            # ê²°ê³¼ ë¶„ì„
            successful = [r for r in results if r["success"]]
            failed = [r for r in results if not r["success"]]
            
            success_rate = len(successful) / len(results) * 100
            avg_time = sum(r["time"] for r in successful) / len(successful) if successful else 0
            
            print(f"\nğŸ“Š Stress Test Results:")
            print(f"   Total Users: {len(results)}")
            print(f"   Successful: {len(successful)} ({success_rate:.1f}%)")
            print(f"   Failed: {len(failed)}")
            print(f"   Avg Response Time: {avg_time:.2f}s")
            
            # ì„±ê³µë¥  ê¸°ì¤€: 90% ì´ìƒ
            assert success_rate >= 90, f"Success rate too low: {success_rate:.1f}%"
            
            # í‰ê·  ì‘ë‹µ ì‹œê°„: 5ì´ˆ ì´ë‚´
            assert avg_time < 5.0, f"Average response time too slow: {avg_time:.2f}s"
9. CI/CD íŒŒì´í”„ë¼ì¸ í†µí•©
9.1 GitHub Actions ì›Œí¬í”Œë¡œìš°
# .github/workflows/playwright-tests.yml
name: Playwright Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 0 * * *'  # ë§¤ì¼ ìì • ì‹¤í–‰

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install playwright pytest-playwright
        playwright install
    
    - name: Start FastAPI server
      run: |
        uvicorn main:app --host 0.0.0.0 --port 8000 &
        sleep 5
      env:
        FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
    
    - name: Run Playwright tests
      run: |
        pytest tests/ -v --html=report.html --self-contained-html
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: playwright-report
        path: |
          report.html
          tests/screenshots/
    
    - name: Notify on failure
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        text: 'Playwright tests failed!'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
9.2 pytest ì„¤ì •
# pytest.ini
[pytest]
asyncio_mode = auto
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

markers =
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    slow: Tests that take more than 5 seconds
    api: API endpoint tests
    db: Database tests

addopts =
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    --html=test_report.html
    --self-contained-html
9.3 ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# run_tests.sh
#!/bin/bash

echo "ğŸš€ Starting StockMaru Playwright Tests"

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
source .env

# FastAPI ì„œë²„ ì‹œì‘
echo "ğŸ”§ Starting FastAPI server..."
uvicorn main:app --host 0.0.0.0 --port 8000 &
SERVER_PID=$!
sleep 5

# ì„œë²„ ìƒíƒœ í™•ì¸
curl -s http://localhost:8000/ > /dev/null
if [ $? -ne 0 ]; then
    echo "âŒ Server failed to start"
    kill $SERVER_PID
    exit 1
fi

echo "âœ… Server started (PID: $SERVER_PID)"

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "ğŸ§ª Running tests..."

# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
pytest tests/test_api_endpoints.py -v -m api

# í†µí•© í…ŒìŠ¤íŠ¸
pytest tests/test_database.py -v -m db

# E2E í…ŒìŠ¤íŠ¸
pytest tests/test_e2e_scenarios.py -v -m e2e

# ì„œë²„ ì¢…ë£Œ
echo "ğŸ›‘ Stopping server..."
kill $SERVER_PID

echo "âœ… All tests completed!"
10. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ì´ë“œ
10.1 ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/ -v

# íŠ¹ì • ë§ˆì»¤ë§Œ ì‹¤í–‰
pytest tests/ -m api        # API í…ŒìŠ¤íŠ¸ë§Œ
pytest tests/ -m db         # DB í…ŒìŠ¤íŠ¸ë§Œ
pytest tests/ -m e2e        # E2E í…ŒìŠ¤íŠ¸ë§Œ

# ë³‘ë ¬ ì‹¤í–‰ (ì†ë„ í–¥ìƒ)
pytest tests/ -n 4          # 4ê°œ ì›Œì»¤ ì‚¬ìš©
10.2 ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# íŠ¹ì • íŒŒì¼ ì‹¤í–‰
pytest tests/test_api_endpoints.py -v

# íŠ¹ì • í´ë˜ìŠ¤ ì‹¤í–‰
pytest tests/test_api_endpoints.py::TestBalanceEndpoints -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì‹¤í–‰
pytest tests/test_api_endpoints.py::TestBalanceEndpoints::test_get_balance -v
10.3 ë¦¬í¬íŠ¸ ìƒì„±
# HTML ë¦¬í¬íŠ¸
pytest tests/ --html=report.html --self-contained-html

# Coverage ë¦¬í¬íŠ¸
pytest tests/ --cov=. --cov-report=html

# JUnit XML (CI/CDìš©)
pytest tests/ --junitxml=test_results.xml
11. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼
í…ŒìŠ¤íŠ¸ ê²°ê³¼ ëŒ€ì‹œë³´ë“œ
# tests/generate_report.py
import json
from datetime import datetime

def generate_test_report(results):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
    report = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "total": len(results),
            "passed": len([r for r in results if r["passed"]]),
            "failed": len([r for r in results if not r["passed"]]),
            "success_rate": 0
        },
        "details": results
    }
    
    report["summary"]["success_rate"] = (
        report["summary"]["passed"] / report["summary"]["total"] * 100
    )
    
    # JSON ì €ì¥
    with open("test_report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    # ì½˜ì†” ì¶œë ¥
    print("\n" + "="*50)
    print("ğŸ“Š TEST REPORT")
    print("="*50)
    print(f"Total Tests: {report['summary']['total']}")
    print(f"âœ… Passed: {report['summary']['passed']}")
    print(f"âŒ Failed: {report['summary']['failed']}")
    print(f"Success Rate: {report['summary']['success_rate']:.1f}%")
    print("="*50)
    
    return report
ğŸ“‹ ìš”ì•½
Playwrightë¥¼ í™œìš©í•œ StockMaru ê²€ì¦ ì „ëµ:
âœ… í…ŒìŠ¤íŠ¸ ë²”ìœ„
API ì—”ë“œí¬ì¸íŠ¸: ì‘ë‹µ ì½”ë“œ, ë°ì´í„° í˜•ì‹, ì‘ë‹µ ì‹œê°„
ë°ì´í„°ë² ì´ìŠ¤: ë¬´ê²°ì„±, ì—°ì†ì„±, ì˜ˆì¸¡ ì •í™•ë„
AI ëª¨ë¸: êµ¬ì¡°, ì„±ëŠ¥, ì •í™•ë„
ì™¸ë¶€ API: í•œêµ­íˆ¬ìì¦ê¶Œ, Alpha Vantage ì—°ë™
E2E ì‹œë‚˜ë¦¬ì˜¤: ì „ì²´ ë§¤ë§¤ ì›Œí¬í”Œë¡œìš°
ì„±ëŠ¥: ë¶€í•˜ í…ŒìŠ¤íŠ¸, ë™ì‹œì„± ì²˜ë¦¬
ğŸ¯ ê¸°ëŒ€ íš¨ê³¼
ë²„ê·¸ ì¡°ê¸° ë°œê²¬ (ë°°í¬ ì „ 90% ì´ìƒ ê°ì§€)
íšŒê·€ í…ŒìŠ¤íŠ¸ ìë™í™”
API ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
ì‹¤ê±°ë˜ ì „ ì‹œìŠ¤í…œ ì•ˆì •ì„± ë³´ì¥
ğŸš€ ë‹¤ìŒ ë‹¨ê³„
í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶• (pytest.ini, conftest.py)
ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¶€í„° ì ì§„ì  í™•ëŒ€
CI/CD íŒŒì´í”„ë¼ì¸ í†µí•©
ì¼ì¼ ìë™ ì‹¤í–‰ ë° ë¦¬í¬íŠ¸ ìƒì„±